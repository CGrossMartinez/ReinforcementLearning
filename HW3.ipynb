{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#***Carlos Gross-Martinez***\n",
        "#***Reinforcement Learning***\n",
        "#***Link to Google Collab Notebook***\n",
        "#https://colab.research.google.com/drive/14hB9zD2T_AmFcLSHYLDm0HG4WVFojXKJ?usp=sharing"
      ],
      "metadata": {
        "id": "iBxayR5mXY_k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N41G9V1OXTVD",
        "outputId": "bab60463-d4cb-4898-c3b1-85cb053a5d6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q(S,A) Table on iteration 1:\n",
            "  State   Up  Down  Left  Right\n",
            "0    s0  0.0   0.0   0.0  -75.0\n",
            "1    s1  0.0   0.0   0.0    0.0\n",
            "2    s2  0.0   0.0   0.0    0.0\n",
            "3    s3  0.0  12.5   0.0    0.0\n",
            "4    s4  0.0   0.0   0.0    0.0\n",
            "5    s5  0.0   0.0   0.0    0.0\n",
            "6    s6  0.0   0.0   0.0    0.0\n",
            "7    s7  0.0   0.0   0.0    0.0\n",
            "8    s8  0.0   0.0   0.0    0.0\n",
            "\n",
            "Q(S,A) Table on iteration 5:\n",
            "  State        Up       Down      Left  Right\n",
            "0    s0  0.329590   0.674438  0.137329 -78.75\n",
            "1    s1  0.000000   0.000000  0.000000   0.00\n",
            "2    s2  0.000000   0.000000  0.000000   0.00\n",
            "3    s3  0.344849  24.218750  0.344849   0.00\n",
            "4    s4  0.000000   0.000000  0.000000   0.00\n",
            "5    s5  0.000000   0.000000  0.000000   0.00\n",
            "6    s6  0.000000   0.000000  0.000000   0.00\n",
            "7    s7  0.000000   0.000000  0.000000   0.00\n",
            "8    s8  0.000000   0.000000  0.000000   0.00\n",
            "\n",
            "Q(S,A) Table on iteration 10:\n",
            "  State        Up       Down      Left      Right\n",
            "0    s0  0.104284   0.134814  0.081861 -79.921875\n",
            "1    s1  0.000000   0.000000  0.000000   0.000000\n",
            "2    s2  0.000000   0.000000  0.000000   0.000000\n",
            "3    s3  0.102007  24.951172  0.102007   0.000000\n",
            "4    s4  0.000000   0.000000  0.000000   0.000000\n",
            "5    s5  0.000000   0.000000  0.000000   0.000000\n",
            "6    s6  0.000000   0.000000  0.000000   0.000000\n",
            "7    s7  0.000000   0.000000  0.000000   0.000000\n",
            "8    s8  0.000000   0.000000  0.000000   0.000000\n",
            "\n",
            "Q(S,A) Final Table:\n",
            "  State             Up           Down           Left         Right\n",
            "0    s0  5.164138e-144  3.848749e-144  3.870018e-144 -8.000000e+01\n",
            "1    s1   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00\n",
            "2    s2   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00\n",
            "3    s3  3.604286e-144   2.500000e+01  4.299355e-144  1.640265e-27\n",
            "4    s4  -8.000000e+01  -1.000000e+02   3.280530e-27  5.000000e+01\n",
            "5    s5   1.000000e+02   8.000000e+01   1.345017e-25  2.672557e-75\n",
            "6    s6   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00\n",
            "7    s7   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00\n",
            "8    s8   0.000000e+00   0.000000e+00   0.000000e+00  0.000000e+00\n"
          ]
        }
      ],
      "source": [
        "#import library\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#function that translate corrdinates to states\n",
        "def states (coordinates):\n",
        "\n",
        "    if coordinates[0] == 0 and coordinates[1] == 0: #top left cell\n",
        "        state = \"s0\"\n",
        "\n",
        "    elif coordinates[0] == 0 and coordinates[1] == 1: #top center cell / final state R = -80\n",
        "        state = \"s1\"\n",
        "\n",
        "    elif coordinates[0] == 0 and coordinates[1] == 2: #top right cell / final state R = +100\n",
        "        state = \"s2\"\n",
        "\n",
        "    elif coordinates[0] == 1 and coordinates[1] == 0: #middle left cell\n",
        "        state = \"s3\"\n",
        "\n",
        "    elif coordinates[0] == 1 and coordinates[1] == 1: #middle center cell\n",
        "        state = \"s4\"\n",
        " \n",
        "    elif coordinates[0] == 1 and coordinates[1] == 2: #middle right cell\n",
        "        state = \"s5\"\n",
        "\n",
        "    elif coordinates[0] == 2 and coordinates[1] == 0: #bottom left cell / final state R = 25\n",
        "        state = \"s6\"\n",
        "\n",
        "    elif coordinates[0] == 2 and coordinates[1] == 1: #bottom center cell / final state R = -100\n",
        "        state = \"s7\"\n",
        "\n",
        "    else:\n",
        "        state = \"s8\" #bottom right cell / final state R = +80\n",
        "\n",
        "    return state\n",
        "\n",
        "#function that calculates the possibkle actions based on states\n",
        "def possible_actions(current_state):\n",
        "\n",
        "    #actions: up 1, down = 2, left = 3, right = 4  \n",
        "    actions = (1, 2, 3, 4)\n",
        "    \n",
        "    return actions\n",
        "\n",
        "#function that calculates the next state\n",
        "def calc_next_state(act, cur_loc):\n",
        "\n",
        "    temp = np.zeros(2)\n",
        "\n",
        "    #condition that provides coordinates of next state\n",
        "    #actions: up 1, down = 2, left = 3, right = 4\n",
        "    if act == 1:\n",
        "        if cur_loc[0] > 0:\n",
        "            temp[1] = cur_loc[1]\n",
        "            temp[0] = cur_loc[0] - 1\n",
        "            \n",
        "    elif act == 2:\n",
        "        if cur_loc[0] < 2:\n",
        "            temp[1] = cur_loc[1]\n",
        "            temp[0] = cur_loc[0] + 1\n",
        "\n",
        "    elif act == 3:\n",
        "        if cur_loc[1] > 0:\n",
        "            temp[0] = cur_loc[0]\n",
        "            temp[1] = cur_loc[1] - 1\n",
        "    else:\n",
        "        if cur_loc[1] < 2:\n",
        "            temp[0] = cur_loc[0]\n",
        "            temp[1] = cur_loc[1] + 1\n",
        "\n",
        "    return temp\n",
        "\n",
        "\n",
        "#function that returns the index of the state in qSA table     \n",
        "def cal_state_index (curr_st, qSA):\n",
        "\n",
        "    for i in range(len(qSA)):\n",
        "        if qSA[i][0] == curr_st:\n",
        "            return i\n",
        "\n",
        "#function that compares all rewards from actions in next state and returns max value\n",
        "def get_max_act_next_st(next_state, qSA):\n",
        "\n",
        "    temp_max = 0\n",
        "\n",
        "    for i in range (len(qSA)):\n",
        "        if qSA[i][0] == next_state:\n",
        "            for j in range(1, 5):                \n",
        "                if temp_max < qSA[i][j]:\n",
        "                    return qSA[i][j]\n",
        "\n",
        "    return temp_max\n",
        "\n",
        "#function that updates the qSA table and calculates error\n",
        "def update_qSA(curr_st, next_state, action, qSA, rewards):\n",
        "\n",
        "    alpha = 0.5\n",
        "    gamma = 0.5\n",
        "\n",
        "    cur_st_id_qSA = cal_state_index(curr_st, qSA)\n",
        "\n",
        "    #Qlearning equation calculation\n",
        "    qSA[cur_st_id_qSA][action] = ((1 - alpha) * qSA[cur_st_id_qSA][action]) + alpha * (rewards[cur_st_id_qSA][action] + (gamma * get_max_act_next_st(next_state, qSA)))\n",
        "\n",
        "    #calculating error of current iteration\n",
        "    current_iter_error.append(abs(get_max_act_next_st(next_state, qSA) - qSA[cur_st_id_qSA][action]))\n",
        "\n",
        "#funnction that randomly selects an 30% exploration and 70% greedy\n",
        "def select_action(cur_cdnt, curr_st, poss_act, qSA, rewards):\n",
        "\n",
        "    #condition that selects greedy or exploration actions\n",
        "    if np.random.uniform(0, 1) <= 0.3:\n",
        "\n",
        "        #if the condition is exploration, chose random action\n",
        "        rand_action = np.random.choice(poss_act)\n",
        "        next_state_coordinate = calc_next_state(rand_action, cur_cdnt)\n",
        "        next_state = states(next_state_coordinate)\n",
        "        update_qSA(curr_st, next_state, rand_action, qSA, rewards)\n",
        "        return rand_action\n",
        "\n",
        "    else:\n",
        "\n",
        "        #if the condition is greedy, traverse through all possible actions\n",
        "        #to determine best action\n",
        "        for actions in poss_act:\n",
        "\n",
        "            next_state_coordinate = calc_next_state(actions, cur_cdnt)\n",
        "            next_state = states(next_state_coordinate)\n",
        "            update_qSA(curr_st, next_state, actions, qSA, rewards)\n",
        "\n",
        "    #selecting a ramdon action initially\n",
        "    action = np.random.choice(poss_act)\n",
        "    cur_st_id = cal_state_index (curr_st, qSA)\n",
        "\n",
        "    #setting temp_max to initial qSA value\n",
        "    temp_max = qSA[cur_st_id][1]\n",
        "\n",
        "    #traversing through qSA value for action to find the greediest\n",
        "    for i in range(2, 5):\n",
        "\n",
        "        if temp_max < qSA[cur_st_id][i]:\n",
        "            action = i\n",
        "            temp_max = qSA[cur_st_id][i]\n",
        "\n",
        "    return action\n",
        "\n",
        "#function that checks if the current state is a goal stater\n",
        "def is_goal (current_state, goal_state):\n",
        "\n",
        "    return all(current_state == goal_state)\n",
        "\n",
        "#function that print qSA table based on iteration\n",
        "def printqSA(iter_count):\n",
        "\n",
        "    df = pd.DataFrame(qSA, columns = ['State', 'Up', 'Down', 'Left', 'Right'])\n",
        "\n",
        "    print('')\n",
        "    print('Q(S,A) Table on iteration ' + str(iter_count) + ':')\n",
        "    print(df)\n",
        "\n",
        "##########################################################\n",
        "#Code starts\n",
        "##########################################################\n",
        "\n",
        "#actions: up 1, down = 2, left = 3, right = 4\n",
        "#declaration and initialization of rewards table\n",
        "rewards = ((\"s0\", 0, 0, 0, -80),\n",
        "           (\"s1\", 0, 0, 0, 0),\n",
        "           (\"s2\", 0, 0, 0, 0),\n",
        "           (\"s3\", 0, 25, 0, 0),\n",
        "           (\"s4\", -80, -100, 0, 0),\n",
        "           (\"s5\", 100, 80, 0, 0),\n",
        "           (\"s6\", 0, 0, 0, 0),\n",
        "           (\"s7\", 0, 0, 0, 0),\n",
        "           (\"s8\", 0, 0, 0, 0),\n",
        "          )\n",
        "\n",
        "#declaration and initialization of qSA table\n",
        "qSA = [[\"s0\", 0, 0, 0, 0],\n",
        "       [\"s1\", 0, 0, 0, 0],\n",
        "       [\"s2\", 0, 0, 0, 0],\n",
        "       [\"s3\", 0, 0, 0, 0],\n",
        "       [\"s4\", 0, 0, 0, 0],\n",
        "       [\"s5\", 0, 0, 0, 0],\n",
        "       [\"s6\", 0, 0, 0, 0],\n",
        "       [\"s7\", 0, 0, 0, 0],\n",
        "       [\"s8\", 0, 0, 0, 0],\n",
        "      ]\n",
        "\n",
        "#declaration and initialization of variables\n",
        "goal_coordinate = [[0,1], [0,2], [2,0], [2,1], [2,2]]\n",
        "start_coordinate = [0,0]\n",
        "current_state_coordinate = []\n",
        "\n",
        "iteration = []\n",
        "error_list = []\n",
        "steps_list = []\n",
        "\n",
        "#conducting 1000 iterations of program\n",
        "for i in range(0, 1000):\n",
        "\n",
        "    #declaration and initialization of variables\n",
        "    steps = 0\n",
        "    found_goal = False\n",
        "    current_iter_error = []\n",
        "    current_state_coordinate = start_coordinate\n",
        "\n",
        "    #loop that will not stop until goal coordinate is entered\n",
        "    while found_goal!= True:\n",
        "\n",
        "        #determining current state from coordinates\n",
        "        curr_st = states(current_state_coordinate)\n",
        "\n",
        "        #calculating possible moves based on location\n",
        "        poss_act = possible_actions(curr_st)\n",
        "\n",
        "        #determinig action to complete\n",
        "        action = select_action(current_state_coordinate, curr_st, poss_act, qSA, rewards)\n",
        "\n",
        "        #updating coordinates to the ones in thext state\n",
        "        current_state_coordinate = calc_next_state(action, current_state_coordinate)\n",
        "\n",
        "        #counting the steps taken by algorithm\n",
        "        steps += 1\n",
        "\n",
        "        #checking if the step is the goal state after making the move\n",
        "        for goals in goal_coordinate:\n",
        "\n",
        "            temp_goal_state = np.array(goals)\n",
        "\n",
        "            #setting found_goal value based on boolean operation results\n",
        "            found_goal = is_goal(current_state_coordinate, temp_goal_state)\n",
        "\n",
        "            #exit loop if arrived at goal state\n",
        "            if found_goal == True:\n",
        "                break\n",
        "\n",
        "    #appending information to list to graph\n",
        "    iteration.append(i)\n",
        "    steps_list.append(steps)\n",
        "    error_list.append(max(current_iter_error))  \n",
        "\n",
        "    #print current qSA table based on the current iteration\n",
        "    if i ==  1 or i == 5 or i == 10:\n",
        "        printqSA(i)\n",
        "\n",
        "#print final qSA table\n",
        "df = pd.DataFrame(qSA, columns = ['State', 'Up', 'Down', 'Left', 'Right'])\n",
        "print('')\n",
        "print('Q(S,A) Final Table:')\n",
        "print(df)"
      ]
    }
  ]
}